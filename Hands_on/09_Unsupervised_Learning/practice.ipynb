{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1\n",
    "- 비슷한 샘플을 모으는 비지도 작업\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2\n",
    "- 데이터분석, 고객분류, 추천시스템, 이미지 분할등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading Olivetti faces from https://ndownloader.figshare.com/files/5976027 to C:\\Users\\dongi\\scikit_learn_data\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "olivetti = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _olivetti_faces_dataset:\n",
      "\n",
      "The Olivetti faces dataset\n",
      "--------------------------\n",
      "\n",
      "`This dataset contains a set of face images`_ taken between April 1992 and \n",
      "April 1994 at AT&T Laboratories Cambridge. The\n",
      ":func:`sklearn.datasets.fetch_olivetti_faces` function is the data\n",
      "fetching / caching function that downloads the data\n",
      "archive from AT&T.\n",
      "\n",
      ".. _This dataset contains a set of face images: https://cam-orl.co.uk/facedatabase.html\n",
      "\n",
      "As described on the original website:\n",
      "\n",
      "    There are ten different images of each of 40 distinct subjects. For some\n",
      "    subjects, the images were taken at different times, varying the lighting,\n",
      "    facial expressions (open / closed eyes, smiling / not smiling) and facial\n",
      "    details (glasses / no glasses). All the images were taken against a dark\n",
      "    homogeneous background with the subjects in an upright, frontal position \n",
      "    (with tolerance for some side movement).\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   =====================\n",
      "    Classes                                40\n",
      "    Samples total                         400\n",
      "    Dimensionality                       4096\n",
      "    Features            real, between 0 and 1\n",
      "    =================   =====================\n",
      "\n",
      "The image is quantized to 256 grey levels and stored as unsigned 8-bit \n",
      "integers; the loader will convert these to floating point values on the \n",
      "interval [0, 1], which are easier to work with for many algorithms.\n",
      "\n",
      "The \"target\" for this database is an integer from 0 to 39 indicating the\n",
      "identity of the person pictured; however, with only 10 examples per class, this\n",
      "relatively small dataset is more interesting from an unsupervised or\n",
      "semi-supervised perspective.\n",
      "\n",
      "The original dataset consisted of 92 x 112, while the version available here\n",
      "consists of 64x64 images.\n",
      "\n",
      "When using these images, please give credit to AT&T Laboratories Cambridge.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(olivetti.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "strat_spilt = StratifiedShuffleSplit(n_splits=1, test_size=40,random_state=42)\n",
    "train_valid_idx, text_idx = next(strat_spilt.split(olivetti.data,olivetti.target))\n",
    "\n",
    "X_train_valid = olivetti.data[train_valid_idx]\n",
    "y_train_valid = olivetti.target[train_valid_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
